from lm import LanguageModel
from corpus import *
import pickle
import numpy as np
import os



def readFile(filename):
	"""
	Read a file, return file data as tokenized in list form.
	Input Parameter : File name containing the Data
	Output Paramater : Tokenized Data in a list form
	"""
	data = []
	dirname = os.path.dirname(os.path.abspath(__file__))
	filename = dirname + filename
	file = open(filename)
	for line in file:
		data.append(tokenize(line))
	return data

def loadPickle():
	"""
	Load saved model after training and get the saved object information
	Output : Saved Language Model 
	"""
	f = open('trained_model_ngram.pkl','rb')
	lm = pickle.load(f)
	f.close()
	return lm

def main():
	model_loaded = False
	while True:
		print("Select one of the option from below : ")
		print("1. Train a Language Model")
		print("2. Generate Sentences from the Trained Model")
		print("3. Calculate Model's Perplexity ")
		print("4. Exit \n")
		option = input()
		if int(option) == 1:
			print("Please Select the Data set on which the Model needs to be trained on.")
			print("1. Twitter Dataset")
			print("2. Facebook Dataset")
			print("3. Instagram Dataset\n")
			dataset = input()
			if int(dataset) == 1:
				path = "/dataset/twitter.txt"
			elif int(dataset) == 2:
				path = "/dataset/facebook.txt"
			else:
				path = "/dataset/instagram.txt"

			n_gram = input("Please enter the value of n in n-gram (Default : 3): ")
			if not n_gram:
				n_gram = 3

			lm = LanguageModel(int(n_gram))
			print("Reading Data...")
			input_data = readFile(path)
			input_data = input_data[:int(0.01 * len(input_data))]  # Taking only 1 % of the total data so as to run on larger values of n
			train_data = input_data[:int(0.8 * len(input_data))]  # forming 80% as the train data
			test_data = input_data[int(0.8 * len(input_data)):]   # forming remaining 30% as test data

			# Saving the test file
			with open("test_data.txt","wb") as fp:
				pickle.dump(test_data, fp)
			print("Entire Data Size : ", len(input_data))
			print("Training Data Size : ", len(train_data))
			print("Test Data : ", len(test_data))
			lm.train(train_data)
			print("Training of a Language Model Completed")
			print("Saving the Model..")
			f = open('trained_model_ngram.pkl','wb')
			pickle.dump(lm, f)
			f.close()
			#np.save('trained_model_ngram.npy',lm)
			print("Model saved")
			model_loaded = False

		elif int(option) == 2:
			print("Loading the Model...")
			# print("model_loaded : ", model_loaded)
			if not model_loaded:
				lm = loadPickle()
				model_loaded = True
			# lm = np.load('trained_model_ngram.npy')
			print("Loaded.")
			beam = input("Do you want to generate sentences using Beam Search ? (Y/n) : ")
			if beam and beam.lower() == 'y':
				lm.beam_flag = True
				beam_size =input("Enter beam size (Default: 10)-\n")
				if beam_size :
					lm.beam_width = int(beam_size)
			else:
				lm.beam_flag = False

			# no_of_Text = input("Please Enter number of sentence you want to generate(Default: 10)-\n")
			# if not no_of_Text:
			# 	no_of_Text = 10

			#no_of_Text = int(no_of_Text)
			seed_option = input("Do you want to give Seed Text or not ? (Y/N) : ")
			if seed_option and seed_option.lower() == 'y':
				seed_text = input("Seed Text based on the N-gram value of the trained_model : ")
				print("Working on sentence generation..")
				generated = []
				generated.append(detokenize(lm.generate(1,seed_text)))
				# for i in range(0,int(no_of_Text) - 1):
				# 	generated.append(detokenize(lm.generate()))
			else:
				print("Working on sentence generation..")
				generated = []
				generated.append(detokenize(lm.generate()))
				# for i in range(0,int(no_of_Text)):
				# 	generated.append(detokenize(lm.generate()))

			# print("**********************************************************************************")
			# print("Sentences Generated by the Language Model were : ")
			# for i in range(0,len(generated)):
			# 	print(generated[i])

			print("Sentence Generated : ", generated[0])
			# print("***********************************************************************************")

			print()
			print()
		
		elif int(option) == 3:
			print("Loading Model and Calculating Perplexity")
			lm = loadPickle()
			# Loading the Test Data
			with open("test_data.txt","rb") as fp:
				test_data = pickle.load(fp)
			perplexity_value = lm.perplexity(test_data) 
			print("Perplexity value for the Test Data when n =  ",lm.n_gram, " is : ", perplexity_value)
		else:
			break

if __name__ == '__main__':
	main()
