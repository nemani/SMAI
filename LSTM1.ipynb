{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiegJolRFrfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ad1752d-f941-45f4-87c9-9ecb3f38c81a"
      },
      "source": [
        "import sys,os\n",
        "import io\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uEVoFxaDnCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q pyyaml h5py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI7u69KjFrfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFVAILXvFrf6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6da1b0d5-12d8-4d7a-8f4d-075a521cae34"
      },
      "source": [
        "corpus = \"en_US_3.txt\"\n",
        "with io.open(corpus, encoding='utf-8') as f:\n",
        "    text = f.read().lower().replace('\\n', ' \\n ')\n",
        "print('Corpus length in characters:', len(text))\n",
        "\n",
        "text_in_words = [w for w in text.split(' ') if w.strip() != '' or w == '\\n']\n",
        "print('Corpus length in words:', len(text_in_words))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus length in characters: 4229397\n",
            "Corpus length in words: 818620\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia8Nm7GlFrgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MIN_WORD_FREQUENCY = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwfnhadAFrgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3c3558d6-d3aa-4409-bdab-bf54f8e76176"
      },
      "source": [
        "# Calculate word frequency\n",
        "word_freq = {}\n",
        "for word in text_in_words:\n",
        "    word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "ignored_words = set()\n",
        "for k, v in word_freq.items():\n",
        "    if word_freq[k] < MIN_WORD_FREQUENCY:\n",
        "        ignored_words.add(k)\n",
        "\n",
        "words = set(text_in_words)\n",
        "print('Unique words before ignoring:', len(words))\n",
        "print('Ignoring words with frequency <', MIN_WORD_FREQUENCY)\n",
        "words = sorted(set(words) - ignored_words)\n",
        "print('Unique words after ignoring:', len(words))\n",
        "\n",
        "word_indices = dict((c, i) for i, c in enumerate(words))\n",
        "indices_word = dict((i, c) for i, c in enumerate(words))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words before ignoring: 86222\n",
            "Ignoring words with frequency < 2\n",
            "Unique words after ignoring: 27195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3aoxeihFrgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEQUENCE_LEN = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a1rrUCqFrgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ba8d26a9-ee7a-4ecb-fea0-e7dba3ad1a83"
      },
      "source": [
        "# cut the text in semi-redundant sequences of SEQUENCE_LEN words\n",
        "STEP = 1\n",
        "sentences = []\n",
        "next_words = []\n",
        "ignored = 0\n",
        "for i in range(0, len(text_in_words) - SEQUENCE_LEN, STEP):\n",
        "    # Only add sequences where no word is in ignored_words\n",
        "    if len(set(text_in_words[i: i+SEQUENCE_LEN+1]).intersection(ignored_words)) == 0:\n",
        "        sentences.append(text_in_words[i: i + SEQUENCE_LEN])\n",
        "        next_words.append(text_in_words[i + SEQUENCE_LEN])\n",
        "    else:\n",
        "        ignored = ignored+1\n",
        "print('Ignored sequences:', ignored)\n",
        "print('Remaining sequences:', len(sentences))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ignored sequences: 437310\n",
            "Remaining sequences: 381300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nUB3vuoFrgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_and_split_training_set(sentences_original, next_original, percentage_test=2):\n",
        "    # shuffle at unison\n",
        "    print('Shuffling sentences')\n",
        "\n",
        "    tmp_sentences = []\n",
        "    tmp_next_word = []\n",
        "    for i in np.random.permutation(len(sentences_original)):\n",
        "        tmp_sentences.append(sentences_original[i])\n",
        "        tmp_next_word.append(next_original[i])\n",
        "\n",
        "    cut_index = int(len(sentences_original) * (1.-(percentage_test/100.)))\n",
        "    x_train, x_test = tmp_sentences[:cut_index], tmp_sentences[cut_index:]\n",
        "    y_train, y_test = tmp_next_word[:cut_index], tmp_next_word[cut_index:]\n",
        "\n",
        "    print(\"Size of training set = %d\" % len(x_train))\n",
        "    print(\"Size of test set = %d\" % len(y_test))\n",
        "    return x_train, y_train,x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fru-iHVSFrg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "47bc10cc-0c54-4dc4-dcd8-fce94bb9e125"
      },
      "source": [
        "sentences, next_words, sentences_test, next_words_test = shuffle_and_split_training_set(sentences, next_words)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shuffling sentences\n",
            "Size of training set = 373674\n",
            "Size of test set = 7626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaHBYoY2FrhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model(dropout = 0.3):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(128), input_shape=(SEQUENCE_LEN, len(words))))\n",
        "    if dropout > 0:\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(len(words)))\n",
        "    print(len(words))\n",
        "    model.add(Activation('softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y30e0om_gaFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LexT9B8fFrhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(sentence_list, next_word_list, batch_size):\n",
        "    index = 0\n",
        "    while True:\n",
        "        x = np.zeros((batch_size, SEQUENCE_LEN, len(words)), dtype=np.bool)\n",
        "        y = np.zeros((batch_size, len(words)), dtype=np.bool)\n",
        "        for i in range(batch_size):\n",
        "            for t, w in enumerate(sentence_list[index]):\n",
        "                x[i, t, word_indices[w]] = 1\n",
        "            y[i, word_indices[next_word_list[index]]] = 1\n",
        "\n",
        "            index = index + 1\n",
        "            if index == len(sentence_list):\n",
        "                index = 0\n",
        "        yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNf4AZ62SjLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examples = \"examples.txt\"\n",
        "examples_file = open(examples, \"w+\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK_562VTFrhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n",
        "\n",
        "    # Randomly pick a seed sequence\n",
        "    seed_index = np.random.randint(len(sentences+sentences_test))\n",
        "    seed = (sentences+sentences_test)[seed_index]\n",
        "\n",
        "    for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "        sentence = seed\n",
        "        examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n",
        "        examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n",
        "        examples_file.write(' '.join(sentence))\n",
        "\n",
        "        for i in range(50):\n",
        "            x_pred = np.zeros((1, SEQUENCE_LEN, len(words)))\n",
        "            for t, word in enumerate(sentence):\n",
        "                x_pred[0, t, word_indices[word]] = 1\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_word = indices_word[next_index]\n",
        "\n",
        "            sentence = sentence[1:]\n",
        "            sentence.append(next_word)\n",
        "\n",
        "            examples_file.write(\" \"+next_word)\n",
        "        examples_file.write('\\n')\n",
        "    examples_file.write('='*80 + '\\n')\n",
        "    examples_file.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mud9NaIvFrhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = \"/content/checkpoints/LSTM_LYRICS-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-loss{loss:.4f}-acc{categorical_accuracy:.4f}-val_loss{val_loss:.4f}-val_acc{val_categorical_accuracy:.4f}\" % (\n",
        "    len(words),\n",
        "    SEQUENCE_LEN,\n",
        "    MIN_WORD_FREQUENCY\n",
        ")\n",
        "checkpoint_dir = os.path.dirname(file_path)\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='categorical_accuracy', save_best_only=True)\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "early_stopping = EarlyStopping(monitor='categorical_accuracy', patience=4)\n",
        "callbacks_list = [checkpoint, print_callback, early_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcJiVplpFrhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "5840f28f-eb8f-4249-c1ef-6da1ab84f4ee"
      },
      "source": [
        "model = define_model()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "27195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM156mOjFrh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuUQ2V2dGkoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3fed4ef4-3341-419e-a812-cb3e14085bb6"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['categorical_accuracy'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST1kR994JqBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "2b72bcd9-76b7-4861-eecc-7501a640c45d"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_1 (Bidirection (None, 256)               27979776  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 27195)             6989115   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 27195)             0         \n",
            "=================================================================\n",
            "Total params: 34,968,891\n",
            "Trainable params: 34,968,891\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjBm8Fg8FriM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df88be67-19a0-42c7-d20d-62938ce05677"
      },
      "source": [
        "model.fit_generator(generator(sentences, next_words, BATCH_SIZE),\n",
        "    steps_per_epoch=int(len(sentences)/BATCH_SIZE) + 1,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks_list,\n",
        "    validation_data=generator(sentences_test, next_words_test, BATCH_SIZE),\n",
        "                    validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "748/748 [==============================] - 642s 858ms/step - loss: 7.1826 - categorical_accuracy: 0.0679 - val_loss: 7.0450 - val_categorical_accuracy: 0.0711\n",
            "Epoch 2/20\n",
            "748/748 [==============================] - 634s 848ms/step - loss: 6.8263 - categorical_accuracy: 0.0810 - val_loss: 6.6899 - val_categorical_accuracy: 0.1119\n",
            "Epoch 3/20\n",
            "748/748 [==============================] - 636s 851ms/step - loss: 6.3676 - categorical_accuracy: 0.1308 - val_loss: 6.4339 - val_categorical_accuracy: 0.1385\n",
            "Epoch 4/20\n",
            "748/748 [==============================] - 636s 850ms/step - loss: 6.0412 - categorical_accuracy: 0.1518 - val_loss: 6.3334 - val_categorical_accuracy: 0.1475\n",
            "Epoch 5/20\n",
            "748/748 [==============================] - 635s 848ms/step - loss: 5.7663 - categorical_accuracy: 0.1674 - val_loss: 6.3246 - val_categorical_accuracy: 0.1484\n",
            "Epoch 6/20\n",
            "748/748 [==============================] - 634s 848ms/step - loss: 5.4892 - categorical_accuracy: 0.1824 - val_loss: 6.3670 - val_categorical_accuracy: 0.1455\n",
            "Epoch 7/20\n",
            "748/748 [==============================] - 635s 848ms/step - loss: 5.2116 - categorical_accuracy: 0.1979 - val_loss: 6.5029 - val_categorical_accuracy: 0.1408\n",
            "Epoch 8/20\n",
            "748/748 [==============================] - 636s 851ms/step - loss: 4.9408 - categorical_accuracy: 0.2142 - val_loss: 6.6048 - val_categorical_accuracy: 0.1369\n",
            "Epoch 9/20\n",
            "748/748 [==============================] - 636s 850ms/step - loss: 4.6822 - categorical_accuracy: 0.2325 - val_loss: 6.7198 - val_categorical_accuracy: 0.1338\n",
            "Epoch 10/20\n",
            "748/748 [==============================] - 635s 849ms/step - loss: 4.4299 - categorical_accuracy: 0.2532 - val_loss: 6.8940 - val_categorical_accuracy: 0.1233\n",
            "Epoch 11/20\n",
            "748/748 [==============================] - 635s 849ms/step - loss: 4.1775 - categorical_accuracy: 0.2768 - val_loss: 7.0240 - val_categorical_accuracy: 0.1141\n",
            "Epoch 12/20\n",
            "748/748 [==============================] - 637s 852ms/step - loss: 3.9392 - categorical_accuracy: 0.3034 - val_loss: 7.1381 - val_categorical_accuracy: 0.1118\n",
            "Epoch 13/20\n",
            "748/748 [==============================] - 638s 853ms/step - loss: 3.6963 - categorical_accuracy: 0.3333 - val_loss: 7.2856 - val_categorical_accuracy: 0.1104\n",
            "Epoch 14/20\n",
            "748/748 [==============================] - 636s 851ms/step - loss: 3.4703 - categorical_accuracy: 0.3625 - val_loss: 7.4452 - val_categorical_accuracy: 0.1078\n",
            "Epoch 15/20\n",
            "748/748 [==============================] - 632s 846ms/step - loss: 3.2603 - categorical_accuracy: 0.3917 - val_loss: 7.6174 - val_categorical_accuracy: 0.1031\n",
            "Epoch 16/20\n",
            "748/748 [==============================] - 628s 839ms/step - loss: 3.0724 - categorical_accuracy: 0.4195 - val_loss: 7.7535 - val_categorical_accuracy: 0.1023\n",
            "Epoch 17/20\n",
            "748/748 [==============================] - 631s 844ms/step - loss: 2.8897 - categorical_accuracy: 0.4471 - val_loss: 7.8411 - val_categorical_accuracy: 0.1011\n",
            "Epoch 18/20\n",
            "748/748 [==============================] - 634s 847ms/step - loss: 2.7034 - categorical_accuracy: 0.4777 - val_loss: 8.0010 - val_categorical_accuracy: 0.1012\n",
            "Epoch 19/20\n",
            "748/748 [==============================] - 633s 847ms/step - loss: 2.5376 - categorical_accuracy: 0.5031 - val_loss: 8.1725 - val_categorical_accuracy: 0.0970\n",
            "Epoch 20/20\n",
            "748/748 [==============================] - 634s 848ms/step - loss: 2.3953 - categorical_accuracy: 0.5255 - val_loss: 8.3174 - val_categorical_accuracy: 0.0903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f715df7ec18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-_k5qMuGem6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "009c1b95-c21c-44f7-b1fc-4adc088ebca6"
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM_LYRICS-epoch001-words27195-sequence10-minfreq2-loss7.1826-acc0.0679-val_loss7.0450-val_acc0.0711\n",
            "LSTM_LYRICS-epoch002-words27195-sequence10-minfreq2-loss6.8263-acc0.0810-val_loss6.6899-val_acc0.1119\n",
            "LSTM_LYRICS-epoch003-words27195-sequence10-minfreq2-loss6.3676-acc0.1308-val_loss6.4339-val_acc0.1385\n",
            "LSTM_LYRICS-epoch004-words27195-sequence10-minfreq2-loss6.0412-acc0.1518-val_loss6.3334-val_acc0.1475\n",
            "LSTM_LYRICS-epoch005-words27195-sequence10-minfreq2-loss5.7663-acc0.1674-val_loss6.3246-val_acc0.1484\n",
            "LSTM_LYRICS-epoch006-words27195-sequence10-minfreq2-loss5.4892-acc0.1824-val_loss6.3670-val_acc0.1455\n",
            "LSTM_LYRICS-epoch007-words27195-sequence10-minfreq2-loss5.2116-acc0.1979-val_loss6.5029-val_acc0.1408\n",
            "LSTM_LYRICS-epoch008-words27195-sequence10-minfreq2-loss4.9408-acc0.2142-val_loss6.6048-val_acc0.1369\n",
            "LSTM_LYRICS-epoch009-words27195-sequence10-minfreq2-loss4.6822-acc0.2325-val_loss6.7198-val_acc0.1338\n",
            "LSTM_LYRICS-epoch010-words27195-sequence10-minfreq2-loss4.4299-acc0.2532-val_loss6.8940-val_acc0.1233\n",
            "LSTM_LYRICS-epoch011-words27195-sequence10-minfreq2-loss4.1775-acc0.2768-val_loss7.0240-val_acc0.1141\n",
            "LSTM_LYRICS-epoch012-words27195-sequence10-minfreq2-loss3.9392-acc0.3034-val_loss7.1381-val_acc0.1118\n",
            "LSTM_LYRICS-epoch013-words27195-sequence10-minfreq2-loss3.6963-acc0.3333-val_loss7.2856-val_acc0.1104\n",
            "LSTM_LYRICS-epoch014-words27195-sequence10-minfreq2-loss3.4703-acc0.3625-val_loss7.4452-val_acc0.1078\n",
            "LSTM_LYRICS-epoch015-words27195-sequence10-minfreq2-loss3.2603-acc0.3917-val_loss7.6174-val_acc0.1031\n",
            "LSTM_LYRICS-epoch016-words27195-sequence10-minfreq2-loss3.0724-acc0.4195-val_loss7.7535-val_acc0.1023\n",
            "LSTM_LYRICS-epoch017-words27195-sequence10-minfreq2-loss2.8897-acc0.4471-val_loss7.8411-val_acc0.1011\n",
            "LSTM_LYRICS-epoch018-words27195-sequence10-minfreq2-loss2.7034-acc0.4777-val_loss8.0010-val_acc0.1012\n",
            "LSTM_LYRICS-epoch019-words27195-sequence10-minfreq2-loss2.5376-acc0.5031-val_loss8.1725-val_acc0.0970\n",
            "LSTM_LYRICS-epoch020-words27195-sequence10-minfreq2-loss2.3953-acc0.5255-val_loss8.3174-val_acc0.0903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2VlNsau_TLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/checkpoints/LSTM_LYRICS-epoch005-words27195-sequence10-minfreq2-loss5.7663-acc0.1674-val_loss6.3246-val_acc0.1484\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz6r-pQ8ELuw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0f5c097-c98e-43b2-edea-5f91312f5bd1"
      },
      "source": [
        "loss,acc = model.evaluate(generator(sentences_test,  next_words_test,BATCH_SIZE), verbose=2,steps=int(len(sentences_test)/BATCH_SIZE) + 1)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restored model, accuracy: 14.88%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U7Q9L63BkiD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "cf79b64e-693b-4014-ff71-6ee0e022862a"
      },
      "source": [
        "words_number = 50 # number of words to generate\n",
        "seed_sentences = \"Desk put together, room all set up. Oh boy, oh\" #seed sentence to start the generating.\n",
        "seed_sentences = seed_sentences.lower()\n",
        "#initiate sentences\n",
        "generated = ''\n",
        "sentence = []\n",
        "\n",
        "#we shate the seed accordingly to the neural netwrok needs:\n",
        "for i in range (SEQUENCE_LEN):\n",
        "    sentence.append(\"a\")\n",
        "\n",
        "seed = seed_sentences.split()\n",
        "\n",
        "for i in range(len(seed)):\n",
        "    sentence[SEQUENCE_LEN-i-1]=seed[len(seed)-i-1]\n",
        "\n",
        "generated += ' '.join(sentence)\n",
        "\n",
        "#the, we generate the text\n",
        "for i in range(words_number):\n",
        "    #create the vector\n",
        "    x = np.zeros((1, SEQUENCE_LEN, len(words)))\n",
        "    for t, word in enumerate(sentence):\n",
        "        x[0, t, word_indices[word]] = 1.\n",
        "\n",
        "    #calculate next word\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_index = sample(preds, 0.33)\n",
        "    next_word = indices_word[next_index]\n",
        "\n",
        "    #add the next word to the text\n",
        "    generated += \" \" + next_word\n",
        "    # shift the sentence by one, and and the next word at its end\n",
        "    sentence = sentence[1:] + [next_word]\n",
        "\n",
        "#print the whole text\n",
        "print(generated)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "desk put together, room all set up. oh boy, oh i don't love it \n",
            " i can't wait to see you at the best of the world \n",
            " i love to see you at the world but i think i was like a great service in the rest of the world and the best day is in the way to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_JOsX0WC2Nm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}